McKenna Wirth and Antonia Ritter
CS 338 Spring 2022
Assignment: Brute-Force Password Cracking

Part 1 (conducted on McKenna's faster computer)
Total time: 0m0.232s
Number of hashes computed: 267,751 
Passwords cracked: 2,805
Time per hash computed: 0.00000128s
Time per password cracked: 0.000081996s
Passwords cracked per number of hashes computed: 0.010476

Part 2 (conducted on McKenna's faster computer)
Total time: 14h 18m 8s
Number of hashes computed: 29,428,298,520
Passwords cracked: 1170
Time per hash computed: 0.000001749s
Time per password cracked: 44.007s
Passwords cracked per number of hashes computed: 0.0000000397

Part 3 (conducted on Antonia's computer)
Total time: 13m51.623s
Number of hashes computed: 750,781,883
Passwords cracked: 2,805
Time per hash computed: 0.0000011076759s
Time per password cracked: 0.296478s
Passwords cracked per number of hashes computed: 0.0000037361

Analysis:

- Did your time per hash computed change between phases? By what factor? Why?

No, hashing time stayed fairly consistent across phases.  This is because it relies on the same operation, regardless of the input being hashed (in later parts, the time differential comes from conducting far more hashes).


- Did your time per password crack change between phases? By what factor? Why?

Yes, it increased by a factor of about 500,000 between phases 1 and 2.  This is due to the increased number of hashes to compute (for each word, you need to try it in combination with every other word).  Between phases 1 and 3, in increased by a factor of 1,000.  While the number of hashes required for phase 3 was substantially more than phase 1, but the list of possible salts is shorter than the list of possible words (there are fewer passwords than words in the provided materials).


- Suppose you wanted to precompute all the possible password hashes for each so you could just look up the password in a table indexed by the hash. How much memory would be required for each phase?

For phase 1, for every word in the dictionary, we need to store the word (16 bytes), the hash string (32 bytes), and the mapping (also 32 bytes), for a total of 267751 words.  Therefore, each word requires 80 bytes total.  For the full file of words.txt, which as 267751, we would need 267751*80 bytes = 21.42MB.

For phase 2, these calculations are the same, but there are 267751*267751 possible combinations to hash and store.  Therefore, we would need 267751*267751*80 bytes = 5.735TB.

For phase 3, our program assumes we have access to the full list of salts used in the password formation.  Therefore, we need to store every possible combination of salt and word.  Assuming every entry uses a unique salt, we would have 2805 possible salts.  The total memory needed would then be 267751*2805*80 bytes = 60.08GB. 


- Give 3-4 reasons we should store password hashes and not the passwords themselves. Think in terms of threats, who the attackers might be, etc.

If someone gets the password file and knows the hash method, it still takes a while to brute force the plaintext.

Knowing part of the password is not enough to automatically find the entire plaintext password.

Realistically, different people will use the same password. Salting the hashes means that you cannot simply compare password hashes and find the overlap- you have to hash with the salt. This also reduces the utility of a database of unsalted password hashes, meaning you cannot pre-compute the password hashes without the salt.

Password hashes are set lengths, making it easier to write code that utilizes them.
